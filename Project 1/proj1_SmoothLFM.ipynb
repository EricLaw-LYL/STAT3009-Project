{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "from developed_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\")\n",
    "dtest_submit = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "## mapping \n",
    "from sklearn import preprocessing\n",
    "le_user = preprocessing.LabelEncoder()\n",
    "le_user.fit(np.append(df['user_id'], dtest_submit[\"user_id\"]))\n",
    "df['user_id'] = le_user.transform(df[\"user_id\"])\n",
    "dtest_submit[\"user_id\"] = le_user.transform(dtest_submit[\"user_id\"])\n",
    "\n",
    "le_item = preprocessing.LabelEncoder()\n",
    "le_item.fit(np.append(df['item_id'], dtest_submit[\"item_id\"]))\n",
    "df[\"item_id\"] = le_item.transform(df[\"item_id\"])\n",
    "dtest_submit[\"item_id\"] = le_item.transform(dtest_submit[\"item_id\"])\n",
    "\n",
    "## generate train / test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "dtrain, dtest = train_test_split(df, test_size=0.33, random_state=42)\n",
    "\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pair, train_rating\n",
    "train_pair = dtrain[['user_id', 'item_id']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "\n",
    "# test_pair\n",
    "test_pair = dtest[['user_id', 'item_id']].values\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for user_mean: 1.978\n"
     ]
    }
   ],
   "source": [
    "## baseline user mean methods\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_rating)\n",
    "pred_user = user_ave.predict(test_pair)\n",
    "print('RMSE for user_mean: %.3f' %rmse(test_rating, pred_user) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for item_mean: 2.877\n"
     ]
    }
   ],
   "source": [
    "## baseline item mean methods\n",
    "item_ave = item_mean(n_item=n_item)\n",
    "item_ave.fit(train_pair=train_pair, train_ratings=train_rating)\n",
    "pred_item = item_ave.predict(test_pair)\n",
    "print('RMSE for item_mean: %.3f' %rmse(test_rating, pred_item) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-5f722f15c297>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dtrain['res_rating'] = train_rating_res\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 1.677, valid_rmse: 2.052\n",
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 1.642, valid_rmse: 2.103\n",
      "3-Fold CV for K: 2; lam: 0.00000: train_rmse: 1.675, valid_rmse: 2.074\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-5f722f15c297>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mKs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mshiing_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLFM_CV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mKs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mshiing_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pair\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rating_res\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mshiing_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mshiing_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lyle-\\Documents\\GitHub\\STAT3009-Project\\Project 1\\developed_methods.py\u001b[0m in \u001b[0;36mgrid_search\u001b[1;34m(self, train_pair, train_rating)\u001b[0m\n\u001b[0;32m    152\u001b[0m                                 \u001b[1;31m# fit the model based on CV data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                                 \u001b[0mmodel_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLFM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_user\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_item\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlam\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                                 \u001b[0mmodel_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_pair_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_rating_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m                                 \u001b[0mtrain_rmse_tmp_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_pair_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_rating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_rating_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m                                 \u001b[0mvalid_rmse_tmp_cv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_tmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pair\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_pair_cv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_rating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_rating_cv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lyle-\\Documents\\GitHub\\STAT3009-Project\\Project 1\\developed_methods.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_pair, train_rating, learning_rate)\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m                 \u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrating_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_rating\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m                 \u001b[0merr_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrating_tmp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0merr_tmp\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlam\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0merr_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrating_tmp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## CV based on `LFM_CV`\n",
    "## Baseline + LFM\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "# user_mean\n",
    "train_rating_cm = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_rating_cm)\n",
    "train_rating_res = train_rating_cm - user_ave.predict(train_pair)\n",
    "dtrain['res_rating'] = train_rating_res\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "# fit LFM_CV by residual ratings \n",
    "Ks, lams = [2, 3, 5], 10**np.arange(-6, -2, .5)\n",
    "shiing_cv = LFM_CV(n_user, n_item, cv=3, Ks=Ks, lams=lams)\n",
    "shiing_cv.grid_search(train_pair, train_rating_res)\n",
    "shiing_cv.plot_grid('valid')\n",
    "shiing_cv.plot_grid('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## refit the best model, and make prediction\n",
    "best_K, best_lam = int(shiing_cv.best_model['K']), shiing_cv.best_model['lam']\n",
    "print('best K: %d, best lam: %.5f' %(best_K, best_lam))\n",
    "shiing=LFM(n_user, n_item, K=best_K, lam=best_lam)\n",
    "shiing.fit(train_pair, train_rating_res)\n",
    "pred = pred + shiing.predict(test_pair)\n",
    "print('RMSE for glb + user_mean + LFM: %.3f' %rmse(test_rating, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "user_info = pd.DataFrame({'user_id': list(range(n_user))})\n",
    "user_info = user_info.set_index('user_id')\n",
    "user_info['mean'] = dtrain.groupby('user_id')['res_rating'].mean()\n",
    "user_info['q1'] = dtrain.groupby('user_id')['res_rating'].quantile(.1)\n",
    "user_info['q3'] = dtrain.groupby('user_id')['res_rating'].quantile(.3)\n",
    "user_info['q5'] = dtrain.groupby('user_id')['res_rating'].quantile(.5)\n",
    "user_info['q7'] = dtrain.groupby('user_id')['res_rating'].quantile(.7)\n",
    "user_info['q7'] = dtrain.groupby('user_id')['res_rating'].quantile(.9)\n",
    "## fill NAN as the column mean\n",
    "user_info = user_info.fillna(user_info.mean())\n",
    "user_scaler = StandardScaler()\n",
    "user_info = user_scaler.fit_transform(user_info)\n",
    "\n",
    "item_info = pd.DataFrame({'item_id': list(range(n_item))})\n",
    "item_info = item_info.set_index('item_id')\n",
    "item_info['mean'] = dtrain.groupby('item_id')['res_rating'].mean()\n",
    "item_info['q1'] = dtrain.groupby('item_id')['res_rating'].quantile(.1)\n",
    "item_info['q3'] = dtrain.groupby('item_id')['res_rating'].quantile(.3)\n",
    "item_info['q5'] = dtrain.groupby('item_id')['res_rating'].quantile(.5)\n",
    "item_info['q7'] = dtrain.groupby('item_id')['res_rating'].quantile(.7)\n",
    "item_info['q7'] = dtrain.groupby('item_id')['res_rating'].quantile(.9)\n",
    "## fill NAN as the column mean\n",
    "item_info = item_info.fillna(item_info.mean())\n",
    "item_scaler = StandardScaler()\n",
    "item_info = item_scaler.fit_transform(item_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_info)\n",
    "print(item_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "user_sim = cosine_similarity(user_info)\n",
    "item_sim = cosine_similarity(item_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = 5\n",
    "index_item = [np.where(train_pair[:,1] == i)[0] for i in range(n_item)]\n",
    "index_user = [np.where(train_pair[:,0] == u)[0] for u in range(n_user)]\n",
    "## augmented data\n",
    "fake_pair, fake_rating = [], []\n",
    "for u in range(n_user):\n",
    "\tprint('UserId: %d' %u)\n",
    "\t### find the top closest users for the user u\n",
    "\ttop_user_tmp = user_sim[u].argsort()[-top:][::-1]\n",
    "\tvalid_user_ind = []\n",
    "\t### extend the records' index for the users\n",
    "\tfor u_tmp in top_user_tmp:\n",
    "\t\tvalid_user_ind.extend(index_user[u_tmp])\n",
    "\t### find observed items under top users\n",
    "\tobs_item_tmp = train_pair[valid_user_ind,1]\n",
    "\tfor i in range(n_item):\n",
    "\t\t### find top items \n",
    "\t\ttop_item_tmp = item_sim[i].argsort()[-top:][::-1]\n",
    "\t\t### find valid item: intersect with top-items and observed item\n",
    "\t\tvalid_item_tmp = np.intersect1d(top_item_tmp, obs_item_tmp)\n",
    "\t\tif len(valid_item_tmp) == 0:\n",
    "\t\t\tcontinue\n",
    "\t\tvalid_item_ind = []\n",
    "\t\tfor i_tmp in valid_item_tmp:\n",
    "\t\t\t### extend all rating index for valid item\n",
    "\t\t\tvalid_item_ind.extend(index_item[i_tmp])\n",
    "\t\t### find index close to (u,i)\n",
    "\t\tvalid_ind = np.intersect1d(valid_user_ind, valid_item_ind)\n",
    "\t\tif len(valid_ind) > 0:\n",
    "\t\t\tfake_pair.append([u,i])\n",
    "\t\t\tfake_rating.append(train_rating_res[valid_ind].mean())\n",
    "fake_pair, fake_rating = np.array(fake_pair), np.array(fake_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_pair, aug_rating_res = np.vstack((train_pair, fake_pair)), np.hstack((train_rating_res, fake_rating))\n",
    "\n",
    "## fit the LFM model with augmentated dataset\n",
    "K, lam = 5, 0.0001\n",
    "sSVD=LFM(n_user, n_item, K=K, lam=lam)\n",
    "sSVD.fit(aug_pair, aug_rating_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5129930097a52138fdc5ab816b09a2f27e944ad02f83c97d5e0e22f93f3b8c3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
