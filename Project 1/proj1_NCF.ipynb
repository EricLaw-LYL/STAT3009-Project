{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STAT3009 Project 1\n",
    "- LAW Yiu Leung Eric       1155149315\n",
    "- LAM Wai Chiu          1155152095"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and load the developed methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from developed_methods import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the raw data\n",
    "- check the `user_id` and `item_id`: mapping `item_id` to a continuous sequence based on `sklean.preprocessing`\n",
    "- use `sklearn.model_selection.train_test_split` to generate `train` and `test` dataset\n",
    "- create `train_pair`,`train_rating`, `test_pair`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv(\"data/train.csv\")\n",
    "dtest = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "## mapping \n",
    "from sklearn import preprocessing\n",
    "le_user = preprocessing.LabelEncoder()\n",
    "le_user.fit(np.append(dtrain['user_id'], dtest[\"user_id\"]))\n",
    "dtrain['user_id'] = le_user.transform(dtrain[\"user_id\"])\n",
    "dtest[\"user_id\"] = le_user.transform(dtest[\"user_id\"])\n",
    "\n",
    "le_item = preprocessing.LabelEncoder()\n",
    "le_item.fit(np.append(dtrain['item_id'], dtest[\"item_id\"]))\n",
    "dtrain[\"item_id\"] = le_item.transform(dtrain[\"item_id\"])\n",
    "dtest[\"item_id\"] = le_item.transform(dtest[\"item_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train_pair, train_rating and test_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_pair, train_rating\n",
    "train_pair = dtrain[['user_id', 'item_id']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "\n",
    "# test_pair\n",
    "test_pair = dtest[['user_id', 'item_id']].values\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impelement deep learning with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n",
    "We embed both users and movies in to 50-dimensional vectors.\n",
    "\n",
    "The model computes a match score between user and movie embeddings via a dot product, and adds a per-movie and per-user bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LFactorNet(keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_size, **kwargs):\n",
    "        super(LFactorNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.glb_bias = tf.Variable(0., trainable=True) \n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_items,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-2),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_items, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias + self.glb_bias\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Baseline + NCF\n",
    "# glb mean\n",
    "glb_ave = glb_mean()\n",
    "glb_ave.fit(train_rating)\n",
    "pred = glb_ave.predict(test_pair)\n",
    "\n",
    "# user_mean\n",
    "train_rating_res = train_rating - glb_ave.predict(train_pair)\n",
    "user_ave = user_mean(n_user=n_user)\n",
    "user_ave.fit(train_pair=train_pair, train_ratings=train_rating_res)\n",
    "pred = pred + user_ave.predict(test_pair)\n",
    "\n",
    "# item_mean\n",
    "train_rating_res -=  user_ave.predict(train_pair)\n",
    "item_ave = item_mean(n_item=n_item)\n",
    "item_ave.fit(train_pair=train_pair, train_ratings=train_rating_res)\n",
    "pred = pred + item_ave.predict(test_pair)\n",
    "\n",
    "train_rating_res -= item_ave.predict(train_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "192/192 [==============================] - 2s 4ms/step - loss: 2.0427 - mae: 0.9057 - rmse: 1.1670 - val_loss: 1.5977 - val_mae: 0.9038 - val_rmse: 1.1702\n",
      "Epoch 2/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.4557 - mae: 0.8999 - rmse: 1.1611 - val_loss: 1.4107 - val_mae: 0.9050 - val_rmse: 1.1724\n",
      "Epoch 3/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3569 - mae: 0.8971 - rmse: 1.1581 - val_loss: 1.3859 - val_mae: 0.9075 - val_rmse: 1.1752\n",
      "Epoch 4/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3368 - mae: 0.8949 - rmse: 1.1554 - val_loss: 1.3876 - val_mae: 0.9093 - val_rmse: 1.1778\n",
      "Epoch 5/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3292 - mae: 0.8926 - rmse: 1.1528 - val_loss: 1.3939 - val_mae: 0.9117 - val_rmse: 1.1806\n",
      "Epoch 6/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3239 - mae: 0.8907 - rmse: 1.1506 - val_loss: 1.4001 - val_mae: 0.9139 - val_rmse: 1.1833\n",
      "Epoch 7/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3191 - mae: 0.8889 - rmse: 1.1485 - val_loss: 1.4066 - val_mae: 0.9162 - val_rmse: 1.1860\n",
      "Epoch 8/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3148 - mae: 0.8874 - rmse: 1.1467 - val_loss: 1.4133 - val_mae: 0.9186 - val_rmse: 1.1888\n",
      "Epoch 9/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.3109 - mae: 0.8860 - rmse: 1.1450 - val_loss: 1.4195 - val_mae: 0.9204 - val_rmse: 1.1914\n",
      "Epoch 10/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3076 - mae: 0.8845 - rmse: 1.1435 - val_loss: 1.4258 - val_mae: 0.9227 - val_rmse: 1.1941\n",
      "Epoch 11/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3045 - mae: 0.8837 - rmse: 1.1421 - val_loss: 1.4318 - val_mae: 0.9246 - val_rmse: 1.1966\n",
      "Epoch 12/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.3016 - mae: 0.8827 - rmse: 1.1409 - val_loss: 1.4379 - val_mae: 0.9266 - val_rmse: 1.1991\n",
      "Epoch 13/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2992 - mae: 0.8815 - rmse: 1.1398 - val_loss: 1.4440 - val_mae: 0.9286 - val_rmse: 1.2017\n",
      "Epoch 14/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2967 - mae: 0.8808 - rmse: 1.1387 - val_loss: 1.4497 - val_mae: 0.9306 - val_rmse: 1.2040\n",
      "Epoch 15/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2946 - mae: 0.8800 - rmse: 1.1378 - val_loss: 1.4554 - val_mae: 0.9324 - val_rmse: 1.2064\n",
      "Epoch 16/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2925 - mae: 0.8791 - rmse: 1.1369 - val_loss: 1.4611 - val_mae: 0.9344 - val_rmse: 1.2088\n",
      "Epoch 17/100\n",
      "192/192 [==============================] - 1s 3ms/step - loss: 1.2906 - mae: 0.8785 - rmse: 1.1361 - val_loss: 1.4665 - val_mae: 0.9364 - val_rmse: 1.2110\n",
      "Epoch 18/100\n",
      "192/192 [==============================] - 1s 4ms/step - loss: 1.2889 - mae: 0.8778 - rmse: 1.1353 - val_loss: 1.4717 - val_mae: 0.9383 - val_rmse: 1.2131\n",
      "Epoch 19/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2874 - mae: 0.8774 - rmse: 1.1346 - val_loss: 1.4770 - val_mae: 0.9400 - val_rmse: 1.2153\n",
      "Epoch 20/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2861 - mae: 0.8769 - rmse: 1.1340 - val_loss: 1.4820 - val_mae: 0.9415 - val_rmse: 1.2174\n",
      "Epoch 21/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2847 - mae: 0.8765 - rmse: 1.1334 - val_loss: 1.4862 - val_mae: 0.9427 - val_rmse: 1.2191\n",
      "Epoch 22/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2834 - mae: 0.8762 - rmse: 1.1329 - val_loss: 1.4906 - val_mae: 0.9439 - val_rmse: 1.2209\n",
      "Epoch 23/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2822 - mae: 0.8757 - rmse: 1.1324 - val_loss: 1.4949 - val_mae: 0.9454 - val_rmse: 1.2227\n",
      "Epoch 24/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2812 - mae: 0.8754 - rmse: 1.1319 - val_loss: 1.4994 - val_mae: 0.9468 - val_rmse: 1.2245\n",
      "Epoch 25/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2801 - mae: 0.8748 - rmse: 1.1314 - val_loss: 1.5037 - val_mae: 0.9486 - val_rmse: 1.2263\n",
      "Epoch 26/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2793 - mae: 0.8749 - rmse: 1.1311 - val_loss: 1.5071 - val_mae: 0.9492 - val_rmse: 1.2276\n",
      "Epoch 27/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2784 - mae: 0.8744 - rmse: 1.1307 - val_loss: 1.5109 - val_mae: 0.9504 - val_rmse: 1.2292\n",
      "Epoch 28/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2776 - mae: 0.8741 - rmse: 1.1303 - val_loss: 1.5152 - val_mae: 0.9519 - val_rmse: 1.2309\n",
      "Epoch 29/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2768 - mae: 0.8739 - rmse: 1.1299 - val_loss: 1.5188 - val_mae: 0.9529 - val_rmse: 1.2324\n",
      "Epoch 30/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2761 - mae: 0.8736 - rmse: 1.1296 - val_loss: 1.5224 - val_mae: 0.9541 - val_rmse: 1.2339\n",
      "Epoch 31/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2757 - mae: 0.8734 - rmse: 1.1293 - val_loss: 1.5272 - val_mae: 0.9554 - val_rmse: 1.2354\n",
      "Epoch 32/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2795 - mae: 0.8733 - rmse: 1.1291 - val_loss: 1.5423 - val_mae: 0.9566 - val_rmse: 1.2368\n",
      "Epoch 33/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2839 - mae: 0.8728 - rmse: 1.1287 - val_loss: 1.5400 - val_mae: 0.9575 - val_rmse: 1.2380\n",
      "Epoch 34/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2810 - mae: 0.8728 - rmse: 1.1285 - val_loss: 1.5438 - val_mae: 0.9585 - val_rmse: 1.2393\n",
      "Epoch 35/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2774 - mae: 0.8728 - rmse: 1.1283 - val_loss: 1.5399 - val_mae: 0.9594 - val_rmse: 1.2405\n",
      "Epoch 36/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2729 - mae: 0.8725 - rmse: 1.1280 - val_loss: 1.5422 - val_mae: 0.9602 - val_rmse: 1.2418\n",
      "Epoch 37/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2729 - mae: 0.8724 - rmse: 1.1278 - val_loss: 1.5478 - val_mae: 0.9612 - val_rmse: 1.2430\n",
      "Epoch 38/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2732 - mae: 0.8722 - rmse: 1.1277 - val_loss: 1.5522 - val_mae: 0.9619 - val_rmse: 1.2441\n",
      "Epoch 39/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2775 - mae: 0.8721 - rmse: 1.1274 - val_loss: 1.5567 - val_mae: 0.9627 - val_rmse: 1.2450\n",
      "Epoch 40/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2747 - mae: 0.8718 - rmse: 1.1272 - val_loss: 1.5557 - val_mae: 0.9637 - val_rmse: 1.2461\n",
      "Epoch 41/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2712 - mae: 0.8719 - rmse: 1.1271 - val_loss: 1.5558 - val_mae: 0.9643 - val_rmse: 1.2471\n",
      "Epoch 42/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2703 - mae: 0.8718 - rmse: 1.1269 - val_loss: 1.5579 - val_mae: 0.9651 - val_rmse: 1.2480\n",
      "Epoch 43/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2704 - mae: 0.8715 - rmse: 1.1267 - val_loss: 1.5622 - val_mae: 0.9655 - val_rmse: 1.2489\n",
      "Epoch 44/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2739 - mae: 0.8713 - rmse: 1.1266 - val_loss: 1.5662 - val_mae: 0.9667 - val_rmse: 1.2501\n",
      "Epoch 45/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2747 - mae: 0.8713 - rmse: 1.1264 - val_loss: 1.5676 - val_mae: 0.9673 - val_rmse: 1.2508\n",
      "Epoch 46/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2720 - mae: 0.8715 - rmse: 1.1263 - val_loss: 1.5684 - val_mae: 0.9677 - val_rmse: 1.2518\n",
      "Epoch 47/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2695 - mae: 0.8712 - rmse: 1.1262 - val_loss: 1.5695 - val_mae: 0.9686 - val_rmse: 1.2526\n",
      "Epoch 48/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2689 - mae: 0.8711 - rmse: 1.1260 - val_loss: 1.5730 - val_mae: 0.9693 - val_rmse: 1.2536\n",
      "Epoch 49/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2701 - mae: 0.8710 - rmse: 1.1259 - val_loss: 1.5767 - val_mae: 0.9699 - val_rmse: 1.2543\n",
      "Epoch 50/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2710 - mae: 0.8710 - rmse: 1.1258 - val_loss: 1.5793 - val_mae: 0.9705 - val_rmse: 1.2551\n",
      "Epoch 51/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2705 - mae: 0.8708 - rmse: 1.1257 - val_loss: 1.5790 - val_mae: 0.9710 - val_rmse: 1.2558\n",
      "Epoch 52/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2690 - mae: 0.8709 - rmse: 1.1256 - val_loss: 1.5802 - val_mae: 0.9713 - val_rmse: 1.2565\n",
      "Epoch 53/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2685 - mae: 0.8706 - rmse: 1.1255 - val_loss: 1.5832 - val_mae: 0.9718 - val_rmse: 1.2570\n",
      "Epoch 54/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2690 - mae: 0.8706 - rmse: 1.1254 - val_loss: 1.5845 - val_mae: 0.9724 - val_rmse: 1.2577\n",
      "Epoch 55/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2716 - mae: 0.8705 - rmse: 1.1253 - val_loss: 1.5884 - val_mae: 0.9730 - val_rmse: 1.2585\n",
      "Epoch 56/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2681 - mae: 0.8704 - rmse: 1.1252 - val_loss: 1.5869 - val_mae: 0.9736 - val_rmse: 1.2592\n",
      "Epoch 57/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2680 - mae: 0.8703 - rmse: 1.1251 - val_loss: 1.5906 - val_mae: 0.9740 - val_rmse: 1.2597\n",
      "Epoch 58/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2678 - mae: 0.8705 - rmse: 1.1250 - val_loss: 1.5917 - val_mae: 0.9744 - val_rmse: 1.2603\n",
      "Epoch 59/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2697 - mae: 0.8703 - rmse: 1.1250 - val_loss: 1.5929 - val_mae: 0.9747 - val_rmse: 1.2609\n",
      "Epoch 60/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2671 - mae: 0.8702 - rmse: 1.1249 - val_loss: 1.5939 - val_mae: 0.9753 - val_rmse: 1.2615\n",
      "Epoch 61/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2685 - mae: 0.8702 - rmse: 1.1247 - val_loss: 1.5987 - val_mae: 0.9757 - val_rmse: 1.2620\n",
      "Epoch 62/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2682 - mae: 0.8701 - rmse: 1.1247 - val_loss: 1.5950 - val_mae: 0.9761 - val_rmse: 1.2626\n",
      "Epoch 63/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2682 - mae: 0.8702 - rmse: 1.1247 - val_loss: 1.5980 - val_mae: 0.9763 - val_rmse: 1.2631\n",
      "Epoch 64/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2674 - mae: 0.8702 - rmse: 1.1245 - val_loss: 1.5982 - val_mae: 0.9766 - val_rmse: 1.2636\n",
      "Epoch 65/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2668 - mae: 0.8701 - rmse: 1.1246 - val_loss: 1.6000 - val_mae: 0.9772 - val_rmse: 1.2642\n",
      "Epoch 66/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2658 - mae: 0.8700 - rmse: 1.1244 - val_loss: 1.6002 - val_mae: 0.9775 - val_rmse: 1.2646\n",
      "Epoch 67/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2658 - mae: 0.8699 - rmse: 1.1244 - val_loss: 1.6010 - val_mae: 0.9779 - val_rmse: 1.2651\n",
      "Epoch 68/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2654 - mae: 0.8700 - rmse: 1.1243 - val_loss: 1.6022 - val_mae: 0.9778 - val_rmse: 1.2654\n",
      "Epoch 69/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2657 - mae: 0.8699 - rmse: 1.1242 - val_loss: 1.6057 - val_mae: 0.9785 - val_rmse: 1.2659\n",
      "Epoch 70/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2666 - mae: 0.8699 - rmse: 1.1242 - val_loss: 1.6081 - val_mae: 0.9786 - val_rmse: 1.2664\n",
      "Epoch 71/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2676 - mae: 0.8698 - rmse: 1.1241 - val_loss: 1.6076 - val_mae: 0.9787 - val_rmse: 1.2666\n",
      "Epoch 72/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2724 - mae: 0.8698 - rmse: 1.1241 - val_loss: 1.6095 - val_mae: 0.9792 - val_rmse: 1.2671\n",
      "Epoch 73/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2650 - mae: 0.8697 - rmse: 1.1241 - val_loss: 1.6072 - val_mae: 0.9796 - val_rmse: 1.2677\n",
      "Epoch 74/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2635 - mae: 0.8697 - rmse: 1.1240 - val_loss: 1.6078 - val_mae: 0.9796 - val_rmse: 1.2679\n",
      "Epoch 75/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2636 - mae: 0.8697 - rmse: 1.1239 - val_loss: 1.6102 - val_mae: 0.9801 - val_rmse: 1.2684\n",
      "Epoch 76/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2680 - mae: 0.8698 - rmse: 1.1239 - val_loss: 1.6181 - val_mae: 0.9801 - val_rmse: 1.2686\n",
      "Epoch 77/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2697 - mae: 0.8695 - rmse: 1.1238 - val_loss: 1.6150 - val_mae: 0.9805 - val_rmse: 1.2690\n",
      "Epoch 78/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2648 - mae: 0.8696 - rmse: 1.1238 - val_loss: 1.6119 - val_mae: 0.9807 - val_rmse: 1.2694\n",
      "Epoch 79/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2631 - mae: 0.8696 - rmse: 1.1238 - val_loss: 1.6121 - val_mae: 0.9810 - val_rmse: 1.2697\n",
      "Epoch 80/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2630 - mae: 0.8696 - rmse: 1.1238 - val_loss: 1.6135 - val_mae: 0.9811 - val_rmse: 1.2699\n",
      "Epoch 81/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2646 - mae: 0.8694 - rmse: 1.1237 - val_loss: 1.6162 - val_mae: 0.9816 - val_rmse: 1.2704\n",
      "Epoch 82/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2643 - mae: 0.8696 - rmse: 1.1236 - val_loss: 1.6156 - val_mae: 0.9815 - val_rmse: 1.2706\n",
      "Epoch 83/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2640 - mae: 0.8695 - rmse: 1.1236 - val_loss: 1.6168 - val_mae: 0.9820 - val_rmse: 1.2710\n",
      "Epoch 84/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2686 - mae: 0.8692 - rmse: 1.1236 - val_loss: 1.6268 - val_mae: 0.9822 - val_rmse: 1.2714\n",
      "Epoch 85/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2719 - mae: 0.8696 - rmse: 1.1235 - val_loss: 1.6283 - val_mae: 0.9822 - val_rmse: 1.2717\n",
      "Epoch 86/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2686 - mae: 0.8693 - rmse: 1.1235 - val_loss: 1.6193 - val_mae: 0.9826 - val_rmse: 1.2719\n",
      "Epoch 87/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2625 - mae: 0.8694 - rmse: 1.1234 - val_loss: 1.6188 - val_mae: 0.9828 - val_rmse: 1.2722\n",
      "Epoch 88/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2622 - mae: 0.8694 - rmse: 1.1234 - val_loss: 1.6193 - val_mae: 0.9830 - val_rmse: 1.2725\n",
      "Epoch 89/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2621 - mae: 0.8695 - rmse: 1.1234 - val_loss: 1.6198 - val_mae: 0.9830 - val_rmse: 1.2727\n",
      "Epoch 90/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2619 - mae: 0.8693 - rmse: 1.1233 - val_loss: 1.6204 - val_mae: 0.9831 - val_rmse: 1.2730\n",
      "Epoch 91/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2621 - mae: 0.8695 - rmse: 1.1234 - val_loss: 1.6213 - val_mae: 0.9833 - val_rmse: 1.2731\n",
      "Epoch 92/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2641 - mae: 0.8694 - rmse: 1.1233 - val_loss: 1.6288 - val_mae: 0.9835 - val_rmse: 1.2734\n",
      "Epoch 93/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2696 - mae: 0.8694 - rmse: 1.1233 - val_loss: 1.6286 - val_mae: 0.9834 - val_rmse: 1.2736\n",
      "Epoch 94/100\n",
      "192/192 [==============================] - 0s 1ms/step - loss: 1.2681 - mae: 0.8693 - rmse: 1.1232 - val_loss: 1.6264 - val_mae: 0.9838 - val_rmse: 1.2739\n",
      "Epoch 95/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2642 - mae: 0.8692 - rmse: 1.1232 - val_loss: 1.6265 - val_mae: 0.9842 - val_rmse: 1.2743\n",
      "Epoch 96/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2643 - mae: 0.8693 - rmse: 1.1231 - val_loss: 1.6247 - val_mae: 0.9841 - val_rmse: 1.2743\n",
      "Epoch 97/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2619 - mae: 0.8692 - rmse: 1.1231 - val_loss: 1.6252 - val_mae: 0.9845 - val_rmse: 1.2747\n",
      "Epoch 98/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2623 - mae: 0.8692 - rmse: 1.1232 - val_loss: 1.6266 - val_mae: 0.9847 - val_rmse: 1.2749\n",
      "Epoch 99/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2629 - mae: 0.8692 - rmse: 1.1231 - val_loss: 1.6283 - val_mae: 0.9846 - val_rmse: 1.2750\n",
      "Epoch 100/100\n",
      "192/192 [==============================] - 0s 2ms/step - loss: 1.2667 - mae: 0.8692 - rmse: 1.1230 - val_loss: 1.6305 - val_mae: 0.9847 - val_rmse: 1.2752\n"
     ]
    }
   ],
   "source": [
    "model = LFactorNet(num_users=n_user, num_items=n_item, embedding_size=50)\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    keras.metrics.MeanAbsoluteError(name='mae'),\n",
    "    keras.metrics.RootMeanSquaredError(name='rmse')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3), \n",
    "    loss=tf.keras.losses.MeanSquaredError(), \n",
    "    metrics=metrics\n",
    ")\n",
    "\n",
    "callbacks = [keras.callbacks.EarlyStopping( \n",
    "    monitor='val_rmse', min_delta=0, patience=5, verbose=1, \n",
    "    mode='auto', baseline=None, restore_best_weights=True)]\n",
    "\n",
    "history = model.fit(\n",
    "    x=train_pair,\n",
    "    y=train_rating_res,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_split=.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.82646314 4.63462502 5.00327688 ... 3.4511113  9.73770997 4.15949607]\n"
     ]
    }
   ],
   "source": [
    "pred_rating = pred + model.predict(test_pair).flatten()\n",
    "pred_rating = np.array(pred_rating)\n",
    "print(pred_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjust the prediction within [0, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust(pred_rating, score_min, score_max):\n",
    "    pred_rating_adjusted = pred_rating.copy()\n",
    "    pred_rating_adjusted[pred_rating > score_max] = score_max\n",
    "    pred_rating_adjusted[pred_rating < score_min] = score_min\n",
    "    return pred_rating_adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rating = adjust(pred_rating, 0, 15)\n",
    "\n",
    "submit = pd.DataFrame({\"id\": range(len(dtest)), \"rating\": pred_rating})\n",
    "submit.to_csv(\"predict/NCF.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5129930097a52138fdc5ab816b09a2f27e944ad02f83c97d5e0e22f93f3b8c3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
