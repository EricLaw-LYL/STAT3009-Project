{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from developed_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = pd.read_csv(\"data/train.csv\")\n",
    "dtest = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "## mapping \n",
    "from sklearn import preprocessing\n",
    "le_user = preprocessing.LabelEncoder()\n",
    "le_user.fit(np.append(dtrain['user_id'], dtest[\"user_id\"]))\n",
    "dtrain['user_id'] = le_user.transform(dtrain[\"user_id\"])\n",
    "dtest[\"user_id\"] = le_user.transform(dtest[\"user_id\"])\n",
    "\n",
    "le_item = preprocessing.LabelEncoder()\n",
    "le_item.fit(np.append(dtrain['item_id'], dtest[\"item_id\"]))\n",
    "dtrain[\"item_id\"] = le_item.transform(dtrain[\"item_id\"])\n",
    "dtest[\"item_id\"] = le_item.transform(dtest[\"item_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the train data into train and test dataset\n",
    "dtest_real = dtest.copy() # create a copy for the real test dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "dtrain, dtest = train_test_split(dtrain, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_pair, train_rating\n",
    "train_pair = dtrain[['user_id', 'item_id']].values\n",
    "train_rating = dtrain['rating'].values\n",
    "\n",
    "## save real ratings for test set for evaluation.\n",
    "test_rating = np.array(dtest['rating'])\n",
    "test_pair = dtest[['user_id', 'item_id']].values\n",
    "\n",
    "## remove the ratings in the test set to simulate prediction\n",
    "dtest = dtest.drop(columns='rating')\n",
    "\n",
    "n_user, n_item = max(train_pair[:,0].max(), test_pair[:,0].max())+1, max(train_pair[:,1].max(), test_pair[:,1].max())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 2: Convert the data to be type that `suprise` could understand\n",
    "# via `reader` in `surprise`\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "# rating_scale is required\n",
    "rating_min = min(train_rating)\n",
    "rating_max = max(train_rating)\n",
    "reader = Reader(rating_scale=(rating_min, rating_max))\n",
    "## this auto-folds dataset\n",
    "surp_train_AF = Dataset.load_from_df(dtrain[['user_id', 'item_id', 'rating']], reader)\n",
    "## this is trainset dataset\n",
    "surp_train = surp_train_AF.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## `surprise` has an issue to cold-start problem when make prediction\n",
    "# define a prediction function to exclude the cold-start users/items\n",
    "def surp_pred(dtest, dtrain, method, cold_start=True):\n",
    "\tgbl_mean = dtrain['rating'].mean()\n",
    "\tuser_lst, item_lst = list(set(dtrain['user_id'])), list(set(dtrain['item_id']))\n",
    "\tsurp_pred_lst = []\n",
    "\tfor _, row in dtest.iterrows():\n",
    "\t\tuser_id, item_id = row['user_id'], row['item_id']\n",
    "\t\tif cold_start:\n",
    "\t\t\trating_tmp = method.estimate(user_id, item_id)\n",
    "\t\telse:\n",
    "\t\t\tif ((row['user_id'] in user_lst) and (row['item_id'] in item_lst)):\n",
    "\t\t\t\trating_tmp = method.estimate(user_id, item_id)\n",
    "\t\t\telse:\n",
    "\t\t\t\trating_tmp = gbl_mean\n",
    "\t\tsurp_pred_lst.append(rating_tmp)\n",
    "\tsurp_pred_lst = np.array(surp_pred_lst)\n",
    "\treturn surp_pred_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "RSME for surprise-baseline: 3.575\n"
     ]
    }
   ],
   "source": [
    "## Step 3: determine the method you want to use\n",
    "# algo 1: baseline\n",
    "from surprise.prediction_algorithms.baseline_only import BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    "algo1 = BaselineOnly()\n",
    "# fit model\n",
    "algo1.fit(surp_train)\n",
    "pred_baseline = surp_pred(dtest, dtrain, algo1)\n",
    "print('RSME for surprise-baseline: %.3f' %rmse(test_rating, pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    split0_test_rmse  split1_test_rmse  split2_test_rmse  mean_test_rmse  \\\n",
      "0           1.663445          1.681649          1.649549        1.664881   \n",
      "1           1.663532          1.681998          1.650212        1.665247   \n",
      "2           1.664459          1.682798          1.652870        1.666709   \n",
      "3           1.669867          1.689716          1.656599        1.672060   \n",
      "4           1.663600          1.681994          1.650850        1.665481   \n",
      "5           1.664451          1.682732          1.650495        1.665893   \n",
      "6           1.666235          1.682637          1.653086        1.667319   \n",
      "7           1.671872          1.687321          1.657810        1.672334   \n",
      "8           1.664358          1.683135          1.651464        1.666319   \n",
      "9           1.663942          1.683778          1.651022        1.666247   \n",
      "10          1.664755          1.684311          1.652819        1.667295   \n",
      "11          1.668539          1.687528          1.657363        1.671143   \n",
      "12          1.663860          1.683430          1.651188        1.666159   \n",
      "13          1.663311          1.682589          1.652032        1.665977   \n",
      "14          1.665697          1.685492          1.654984        1.668724   \n",
      "15          1.668096          1.687434          1.656473        1.670668   \n",
      "\n",
      "    std_test_rmse  rank_test_rmse  mean_fit_time  std_fit_time  \\\n",
      "0        0.013144               1       0.130295      0.036991   \n",
      "1        0.013033               2       0.130447      0.008770   \n",
      "2        0.012321               9       0.111425      0.002254   \n",
      "3        0.013609              15       0.140368      0.001836   \n",
      "4        0.012784               3       0.112748      0.015785   \n",
      "5        0.013200               4       0.118555      0.018248   \n",
      "6        0.012088              11       0.113094      0.002521   \n",
      "7        0.012053              16       0.153264      0.010345   \n",
      "8        0.013004               8       0.116051      0.012106   \n",
      "9        0.013471               7       0.126968      0.005842   \n",
      "10       0.012982              10       0.148707      0.009535   \n",
      "11       0.012452              14       0.148656      0.006077   \n",
      "12       0.013263               6       0.123326      0.010574   \n",
      "13       0.012617               5       0.142681      0.005292   \n",
      "14       0.012638              12       0.121190      0.008567   \n",
      "15       0.012770              13       0.145523      0.010586   \n",
      "\n",
      "    mean_test_time  std_test_time  \\\n",
      "0         0.025731       0.003123   \n",
      "1         0.040195       0.026312   \n",
      "2         0.021836       0.000390   \n",
      "3         0.022482       0.000471   \n",
      "4         0.023963       0.003748   \n",
      "5         0.024800       0.003163   \n",
      "6         0.022159       0.000859   \n",
      "7         0.024791       0.003170   \n",
      "8         0.042325       0.029698   \n",
      "9         0.025636       0.002461   \n",
      "10        0.024243       0.002823   \n",
      "11        0.023620       0.001670   \n",
      "12        0.027446       0.003092   \n",
      "13        0.024967       0.003069   \n",
      "14        0.038522       0.021550   \n",
      "15        0.021639       0.000440   \n",
      "\n",
      "                                               params  param_reg_all  \\\n",
      "0                 {'reg_all': 0.0001, 'n_factors': 2}       0.000100   \n",
      "1                 {'reg_all': 0.0001, 'n_factors': 3}       0.000100   \n",
      "2                 {'reg_all': 0.0001, 'n_factors': 5}       0.000100   \n",
      "3                {'reg_all': 0.0001, 'n_factors': 10}       0.000100   \n",
      "4   {'reg_all': 0.00031622776601683794, 'n_factors...       0.000316   \n",
      "5   {'reg_all': 0.00031622776601683794, 'n_factors...       0.000316   \n",
      "6   {'reg_all': 0.00031622776601683794, 'n_factors...       0.000316   \n",
      "7   {'reg_all': 0.00031622776601683794, 'n_factors...       0.000316   \n",
      "8                  {'reg_all': 0.001, 'n_factors': 2}       0.001000   \n",
      "9                  {'reg_all': 0.001, 'n_factors': 3}       0.001000   \n",
      "10                 {'reg_all': 0.001, 'n_factors': 5}       0.001000   \n",
      "11                {'reg_all': 0.001, 'n_factors': 10}       0.001000   \n",
      "12  {'reg_all': 0.0031622776601683794, 'n_factors'...       0.003162   \n",
      "13  {'reg_all': 0.0031622776601683794, 'n_factors'...       0.003162   \n",
      "14  {'reg_all': 0.0031622776601683794, 'n_factors'...       0.003162   \n",
      "15  {'reg_all': 0.0031622776601683794, 'n_factors'...       0.003162   \n",
      "\n",
      "    param_n_factors  \n",
      "0                 2  \n",
      "1                 3  \n",
      "2                 5  \n",
      "3                10  \n",
      "4                 2  \n",
      "5                 3  \n",
      "6                 5  \n",
      "7                10  \n",
      "8                 2  \n",
      "9                 3  \n",
      "10                5  \n",
      "11               10  \n",
      "12                2  \n",
      "13                3  \n",
      "14                5  \n",
      "15               10  \n",
      "best RMSE score: 1.665\n",
      "best hyperparam: {'reg_all': 0.0001, 'n_factors': 2}\n",
      "RSME for surprise-svd-best: 3.849\n"
     ]
    }
   ],
   "source": [
    "# algo 2: SVD model\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "from surprise.model_selection import GridSearchCV\n",
    "## GS based on CV\n",
    "param_grid = {'reg_all': 10**np.arange(-4, -2, .5), 'n_factors': [2, 3, 5, 10]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
    "gs.fit(surp_train_AF)\n",
    "# cv result \n",
    "results_df = pd.DataFrame.from_dict(gs.cv_results)\n",
    "print(results_df)\n",
    "# best RMSE score\n",
    "print('best RMSE score: %.3f' %gs.best_score['rmse'])\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print('best hyperparam: %s' %gs.best_params['rmse'])\n",
    "# We can now use the algorithm that yields the best rmse:\n",
    "algo2_best = gs.best_estimator['rmse']\n",
    "algo2_best.fit(surp_train)\n",
    "# make prediction\n",
    "pred_svd = surp_pred(dtest, dtrain, algo2_best)\n",
    "print('RSME for surprise-svd-best: %.3f' %rmse(test_rating, pred_svd))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5129930097a52138fdc5ab816b09a2f27e944ad02f83c97d5e0e22f93f3b8c3c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
